{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "import re\n",
    "#from flask import Flask\n",
    "#from flask import jsonify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tokenizer():\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns tokenizer50k.pickle file of the tokenizer trained on amazon reviews\n",
    "    \n",
    "    Parameters:\n",
    "        None\n",
    "        \n",
    "    \n",
    "    Returns:\n",
    "        tokenizer : pickle file containing the tokenizer\n",
    "    \"\"\"\n",
    "    \n",
    "    with open('../SentimentAnalysisModelData/tokenizer50k.pickle', 'rb') as f:\n",
    "        tokenizer = pickle.load(f)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    \n",
    "     \n",
    "    \"\"\"\n",
    "    Returns lstm_model.hdf5 file of the LSTM model trained on amazon reviews\n",
    "    \n",
    "    Parameters:\n",
    "        None\n",
    "        \n",
    "    \n",
    "    Returns:\n",
    "        model : hdf5 file containing the trained model\n",
    "    \"\"\"\n",
    "    \n",
    "    model = tf.keras.models.load_model('../SentimentAnalysisModelData/lstm_model.hdf5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_texts(texts):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns the text removing punctuations, non ascii characters and non-binary digits\n",
    "    \n",
    "    Parameters:\n",
    "        texts(list)            : list containing string elements\n",
    "        \n",
    "    \n",
    "    Returns:\n",
    "        normalized_texts(list) : list containing cleaned string elements  \n",
    "    \"\"\"\n",
    "    \n",
    "    NON_ALPHANUM = re.compile(r'[\\W]')\n",
    "    NON_ASCII = re.compile(r'[^a-z0-1\\s]')\n",
    "    normalized_texts = []\n",
    "    for text in texts:\n",
    "        lower = text.lower()\n",
    "        no_punctuation = NON_ALPHANUM.sub(r' ', lower)\n",
    "        no_non_ascii = NON_ASCII.sub(r'', no_punctuation)\n",
    "        normalized_texts.append(no_non_ascii)\n",
    "    return normalized_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_prediction(model, tokenizer, text):\n",
    "    \n",
    "        \n",
    "    \"\"\"\n",
    "    Returns the sentiment of given text/s based on the polarity score of the sentiment.\n",
    "    \n",
    "    If the polarity score is greater than the threshold then sentence is classified as Positive\n",
    "        otherwise Negative\n",
    "        \n",
    "    Threshold = 0.5\n",
    "    \n",
    "    Parameters:\n",
    "        model                          : deep sequential model trained for sentiment analysis\n",
    "        \n",
    "        tokenizer                      : trained tokenizer\n",
    "        \n",
    "        text(string/list of strings)   : text/s of which the sentiment is to be predicted\n",
    "        \n",
    "    \n",
    "    Returns:\n",
    "        normalized_texts(list) : list containing cleaned string elements  \n",
    "    \"\"\"\n",
    "    \n",
    "    text = [text]\n",
    "    text = normalize_texts(text)\n",
    "    max_length = 257\n",
    "    trunc_type = 'post'\n",
    "    text = tokenizer.texts_to_sequences(text)\n",
    "    text = pad_sequences(text, maxlen=max_length)\n",
    "    score = model.predict(text)[0][0]\n",
    "    score = float(\"{:.3f}\".format(score))\n",
    "    sentiment = 'Positive' if score >= 0.5 else 'Negative'\n",
    "    return sentiment, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing all functions\n",
    "\n",
    "#Loading tokenizer\n",
    "tokenizer = load_tokenizer()\n",
    "\n",
    "#Loading model\n",
    "model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n",
      "0.979\n"
     ]
    }
   ],
   "source": [
    "#Taking input and predicting sentiment\n",
    "\n",
    "#sentence = str(input())\n",
    "sentence = \"Good job Omkar. This is working really nice\"\n",
    "sentiment, score = get_sentiment_prediction(model, tokenizer, sentence)\n",
    "print(sentiment)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
